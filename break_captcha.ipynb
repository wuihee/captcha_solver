{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"C:/Users/wuihee/Desktop/Programming/Projects/CAPTCHA Solver/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = \"iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAIAAACHGsgUAAACJUlEQVR42u3asUoEQQwG4KsFG6sDQQTfwMrisBRsLHwB2xMbxdfwHeysfAhLO1/h3uQcCIzjJJv9ZzazNwuBFMexcOx3M0kmu6v9/tEDjJUTOJZjOZZjOZZjOYFjOZZj6bF9e20Xy8C6O9+l0eGfdPvw7lgNsI6Or3jMILW9WXcrJWCJTIZkmRRfVsGLk23WGyQWhnV99oVIZZ+FvP6frEcshWO6V6aDJKxI1unKUgLfidyL04xifX9epGSGFiHuP0546FJzY+FSqRetGqvcLzKlXnNjZV7cpQLr9PIlxBQynckSq6IakpfogndYwYuY4jYUy2UFlniBAVZ16xC8RBQEi4wClpi/i8ienn+KogDLqsMiDrE46ljEFJsG8qq+c7p5ZUEhdbAMq7r5RCpjahSZMiwlRpdYtvuG6qAZVilZypF5cSxulLWjiJdChqT20YQF5awKL87Bi2MIcSkNHXR0Lz2RgVi6VJNqOLTLoldkQn43xUJHYIxMr4Mplp7UjLH4OTmN4EVM4IgmWzi4V0amdwzIBQfAIq/RwYMJVko2Kxaes5pi1XkR2QGwTCZ/5FWUsCZipUtsEpauYD4sVTpVBKvaiyDEcglK/WEhYTtQHvVSGoWsjSg9G/JEZollPn1HxqogVvVZGsz9Qs5qzWSLlXpNHD8oiay7h6xg8lLmqAbPceEBxuGfSPfgBZIt+F0HWyyEbNkvhrTwUsj8LRqNLPvmFzSTJ2tW3jLKAAAAAElFTkSuQmCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = ['2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "# Mapping characters to integers\n",
    "char_to_num = layers.StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image into 4 letters and save them as pngs.\n",
    "image_data = base64.b64decode(image_data)\n",
    "nparr = np.frombuffer(image_data, np.uint8)\n",
    "image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "for i in range(4):\n",
    "    col = image[:, i * 25:(i + 1) * 25]\n",
    "    cv2.imwrite(f\"./test_captcha/letter{i}.png\", col)\n",
    "\n",
    "data_dir = pathlib.Path('./test_captcha')\n",
    "data_dir = [str(path) for path in data_dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode images.\n",
    "def encode_image(image_path: str):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(data_dir)\n",
    "dataset = (\n",
    "    dataset.map(encode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(16)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :1]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 561ms/step\n",
      "['3', '4', 'E', '6']\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dataset)\n",
    "pred_texts = decode_batch_predictions(preds)\n",
    "print(pred_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
